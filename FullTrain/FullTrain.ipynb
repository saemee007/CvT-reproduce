{"cells":[{"cell_type":"markdown","metadata":{"id":"qDNtWSlfQKyf"},"source":["## Setup Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tP4y4b-YbTcB"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1652879519954,"user":{"displayName":"최새미","userId":"13431835325743060622"},"user_tz":-540},"id":"qV-RRNGuUm-S","outputId":"87659d24-6cd2-4064-e8c0-fc36bd58ef22"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/FinalProject/CvT-main\n"]}],"source":["cd '/content/drive/MyDrive/FinalProject/CvT-main'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10693,"status":"ok","timestamp":1652879533717,"user":{"displayName":"최새미","userId":"13431835325743060622"},"user_tz":-540},"id":"I698kpqFUwV3","outputId":"39a0cf70-de39-4fd5-e1da-8eee4e85f390"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (1.7.1)\n","Requirement already satisfied: torchvision==0.8.2 in /usr/local/lib/python3.7/dist-packages (0.8.2)\n","Requirement already satisfied: torchaudio==0.7.2 in /usr/local/lib/python3.7/dist-packages (0.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.2.0)\n","Requirement already satisfied: numpy in /root/.local/lib/python3.7/site-packages (from torch==1.7.1) (1.19.3)\n","Requirement already satisfied: pillow\u003e=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (6.0)\n"]}],"source":["# Install the same pytorch as the paper\n","!pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 \n","\n","# Install a environment with 'requirement.txt' attached to the paper\n","!python -m pip install -r requirements.txt --user -q \n","\n","# Required for code operation but omitting in the paper\n","!pip install -U PyYAML"]},{"cell_type":"markdown","metadata":{"id":"sqb2QlfVQg1U"},"source":["## Categorize Data by Folder\n"," - See https://seongkyun.github.io/others/2019/03/06/imagenet_dn/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5KziXyV8VzvY"},"outputs":[],"source":["# cd /content/drive/MyDrive/FinalProject/CvT-main/DATASET/imagenet/val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSFrPuBrVu20"},"outputs":[],"source":["# !wget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash"]},{"cell_type":"markdown","metadata":{"id":"3J4OzcWbQh1C"},"source":["## Training ImageNet 1k Data by CvT\n"," - Speed: about 100.0 samples/s\n"," - 1 epoch: 20 Hours\n"," - Train Total 3 epoches"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"gIRcuAUG6mNm"},"outputs":[{"name":"stdout","output_type":"stream","text":["job type: train\n","rank: 0\n","node count: 1\n","master addr: 127.0.0.1\n","=\u003e merge config from experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml\n","=\u003e creating OUTPUT ...\n","=\u003e creating OUTPUT/imagenet/cvt-13-224x224-b32-e3 ...\n","=\u003e setup logger ...\n","2022-05-18 13:13:38,928:[P:2305]:Rank[0/1] =\u003e collecting env info (might take some time)\n","2022-05-18 13:13:41,056:[P:2305]:Rank[0/1] \n","PyTorch version: 1.7.1\n","Is debug build: False\n","CUDA used to build PyTorch: 10.2\n","ROCM used to build PyTorch: N/A\n","\n","OS: Ubuntu 18.04.5 LTS (x86_64)\n","GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n","CMake version: version 3.22.4\n","\n","Python version: 3.7 (64-bit runtime)\n","Is CUDA available: True\n","CUDA runtime version: Could not collect\n","GPU models and configuration: GPU 0: Tesla V100-SXM2-16GB\n","Nvidia driver version: 460.32.03\n","cuDNN version: Probably one of the following:\n","/usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n","/usr/lib/x86_64-linux-gnu/libcudnn.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.0.5\n","HIP runtime version: N/A\n","MIOpen runtime version: N/A\n","\n","Versions of relevant libraries:\n","[pip3] numpy==1.19.3\n","[pip3] torch==1.7.1\n","[pip3] torchaudio==0.7.2\n","[pip3] torchsummary==1.5.1\n","[pip3] torchtext==0.12.0\n","[pip3] torchvision==0.8.2\n","[conda] Could not collect\n","2022-05-18 13:13:41,057:[P:2305]:Rank[0/1] Namespace(cfg='experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml', distributed=False, local_rank=0, num_gpus=1, opts=[], port=9000)\n","2022-05-18 13:13:41,057:[P:2305]:Rank[0/1] AMP:\n","  ENABLED: True\n","  MEMORY_FORMAT: nchw\n","AUG:\n","  COLOR_JITTER: [0.4, 0.4, 0.4, 0.1, 0.0]\n","  DROPBLOCK_BLOCK_SIZE: 7\n","  DROPBLOCK_KEEP_PROB: 1.0\n","  DROPBLOCK_LAYERS: [3, 4]\n","  GAUSSIAN_BLUR: 0.0\n","  GRAY_SCALE: 0.0\n","  INTERPOLATION: 2\n","  MIXCUT: 1.0\n","  MIXCUT_AND_MIXUP: False\n","  MIXCUT_MINMAX: []\n","  MIXUP: 0.8\n","  MIXUP_MODE: batch\n","  MIXUP_PROB: 1.0\n","  MIXUP_SWITCH_PROB: 0.5\n","  RATIO: (0.75, 1.3333333333333333)\n","  SCALE: (0.08, 1.0)\n","  TIMM_AUG:\n","    AUTO_AUGMENT: rand-m9-mstd0.5-inc1\n","    COLOR_JITTER: 0.4\n","    HFLIP: 0.5\n","    INTERPOLATION: bicubic\n","    RE_COUNT: 1\n","    RE_MODE: pixel\n","    RE_PROB: 0.25\n","    RE_SPLIT: False\n","    USE_LOADER: True\n","    USE_TRANSFORM: False\n","    VFLIP: 0.0\n","BASE: ['']\n","CUDNN:\n","  BENCHMARK: True\n","  DETERMINISTIC: False\n","  ENABLED: True\n","DATASET:\n","  DATASET: imagenet\n","  DATA_FORMAT: jpg\n","  LABELMAP: \n","  ROOT: DATASET/imagenet/\n","  SAMPLER: default\n","  TARGET_SIZE: -1\n","  TEST_SET: val\n","  TEST_TSV_LIST: []\n","  TRAIN_SET: train\n","  TRAIN_TSV_LIST: []\n","DATA_DIR: \n","DEBUG:\n","  DEBUG: False\n","DIST_BACKEND: nccl\n","FINETUNE:\n","  BASE_LR: 0.003\n","  BATCH_SIZE: 512\n","  EVAL_EVERY: 3000\n","  FINETUNE: False\n","  FROZEN_LAYERS: []\n","  LR_SCHEDULER:\n","    DECAY_TYPE: step\n","  TRAIN_MODE: True\n","  USE_TRAIN_AUG: False\n","GPUS: (0,)\n","INPUT:\n","  MEAN: [0.485, 0.456, 0.406]\n","  STD: [0.229, 0.224, 0.225]\n","LOSS:\n","  LABEL_SMOOTHING: 0.1\n","  LOSS: softmax\n","MODEL:\n","  INIT_WEIGHTS: True\n","  NAME: cls_cvt\n","  NUM_CLASSES: 1000\n","  PRETRAINED: \n","  PRETRAINED_LAYERS: ['*']\n","  SPEC:\n","    ATTN_DROP_RATE: [0.0, 0.0, 0.0]\n","    CLS_TOKEN: [False, False, True]\n","    DEPTH: [1, 2, 10]\n","    DIM_EMBED: [64, 192, 384]\n","    DROP_PATH_RATE: [0.0, 0.0, 0.1]\n","    DROP_RATE: [0.0, 0.0, 0.0]\n","    INIT: trunc_norm\n","    KERNEL_QKV: [3, 3, 3]\n","    MLP_RATIO: [4.0, 4.0, 4.0]\n","    NUM_HEADS: [1, 3, 6]\n","    NUM_STAGES: 3\n","    PADDING_KV: [1, 1, 1]\n","    PADDING_Q: [1, 1, 1]\n","    PATCH_PADDING: [2, 1, 1]\n","    PATCH_SIZE: [7, 3, 3]\n","    PATCH_STRIDE: [4, 2, 2]\n","    POS_EMBED: [False, False, False]\n","    QKV_BIAS: [True, True, True]\n","    QKV_PROJ_METHOD: ['dw_bn', 'dw_bn', 'dw_bn']\n","    STRIDE_KV: [2, 2, 2]\n","    STRIDE_Q: [1, 1, 1]\n","MODEL_SUMMARY: False\n","MULTIPROCESSING_DISTRIBUTED: True\n","NAME: cvt-13-224x224-b32-e3\n","OUTPUT_DIR: OUTPUT/\n","PIN_MEMORY: True\n","PRINT_FREQ: 500\n","RANK: 0\n","TEST:\n","  BATCH_SIZE_PER_GPU: 32\n","  CENTER_CROP: True\n","  IMAGE_SIZE: [224, 224]\n","  INTERPOLATION: 3\n","  MODEL_FILE: \n","  REAL_LABELS: False\n","  VALID_LABELS: \n","TRAIN:\n","  AUTO_RESUME: True\n","  BATCH_SIZE_PER_GPU: 32\n","  BEGIN_EPOCH: 0\n","  CHECKPOINT: \n","  CLIP_GRAD_NORM: 0.0\n","  DETECT_ANOMALY: False\n","  END_EPOCH: 3\n","  EVAL_BEGIN_EPOCH: 0\n","  GAMMA1: 0.99\n","  GAMMA2: 0.0\n","  IMAGE_SIZE: [224, 224]\n","  LR: 0.00025\n","  LR_SCHEDULER:\n","    ARGS:\n","      cooldown_epochs: 10\n","      decay_rate: 0.1\n","      epochs: 3\n","      min_lr: 1e-05\n","      sched: cosine\n","      warmup_epochs: 5\n","      warmup_lr: 1e-06\n","    METHOD: timm\n","  MOMENTUM: 0.9\n","  NESTEROV: True\n","  OPTIMIZER: adamW\n","  OPTIMIZER_ARGS:\n","    \n","  SAVE_ALL_MODELS: False\n","  SCALE_LR: True\n","  SHUFFLE: True\n","  WD: 0.05\n","  WITHOUT_WD_LIST: ['bn', 'bias', 'ln']\n","VERBOSE: True\n","WORKERS: 6\n","2022-05-18 13:13:41,058:[P:2305]:Rank[0/1] =\u003e using 1 GPUs\n","2022-05-18 13:13:41,058:[P:2305]:Rank[0/1] =\u003e saving config into: OUTPUT/imagenet/cvt-13-224x224-b32-e3/config.yaml\n","2022-05-18 13:13:41,110:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,163:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,164:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,165:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,165:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,165:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,166:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,166:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,166:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,167:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,167:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,168:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,186:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,187:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,187:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,188:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,188:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,189:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,189:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,190:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,190:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,192:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,192:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,194:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,194:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,195:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,195:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,196:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,196:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,197:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,197:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,198:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,198:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,200:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,200:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,202:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,380:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,382:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,382:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,384:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,384:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,386:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,386:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,388:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,388:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,394:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,394:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,400:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,400:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,402:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,402:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,404:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,404:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,406:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,406:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,408:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,408:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,413:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,414:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,419:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,420:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,421:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,422:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,423:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,424:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,425:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,426:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,427:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,428:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,433:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,434:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,439:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,440:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,441:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,442:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,443:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,443:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,445:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,445:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,447:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,447:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,453:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,454:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,459:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,460:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,461:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,461:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,463:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,463:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,465:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,465:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,467:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,467:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,473:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,474:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,479:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,480:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,481:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,481:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,483:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,483:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,485:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,485:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,487:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,487:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,492:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,493:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,498:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,498:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,500:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,500:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,502:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,502:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,504:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,504:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,506:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,506:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,511:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,512:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,517:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,517:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,519:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,519:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,521:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,521:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,523:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,523:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,525:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,525:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,530:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,531:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,536:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,536:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,538:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,538:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,540:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,540:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,542:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,542:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,544:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,544:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,549:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,550:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,555:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,555:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,557:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,557:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,559:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,559:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,561:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,561:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,563:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,563:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,568:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:41,569:[P:2305]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 13:13:41,574:[P:2305]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 13:13:48,327:[P:2305]:Rank[0/1] =\u003e ConvolutionalVisionTransformer(\n","  (stage0): VisionTransformer(\n","    (patch_embed): ConvEmbed(\n","      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n","      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (blocks): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=64, out_features=64, bias=True)\n","          (proj_k): Linear(in_features=64, out_features=64, bias=True)\n","          (proj_v): Linear(in_features=64, out_features=64, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=64, out_features=64, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=64, out_features=256, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=256, out_features=64, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (stage1): VisionTransformer(\n","    (patch_embed): ConvEmbed(\n","      (proj): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (blocks): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_k): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_v): Linear(in_features=192, out_features=192, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=192, out_features=768, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=768, out_features=192, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_k): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_v): Linear(in_features=192, out_features=192, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=192, out_features=768, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=768, out_features=192, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (stage2): VisionTransformer(\n","    (patch_embed): ConvEmbed(\n","      (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (blocks): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","  (head): Linear(in_features=384, out_features=1000, bias=True)\n",")\n","2022-05-18 13:13:48,421:[P:2305]:Rank[0/1] Trainable Model Total Parameter: \t20.0M\n","=\u003e set bias(stage0.patch_embed.proj.bias) wd to 0\n","=\u003e set norm(stage0.patch_embed.norm.weight) wd to 0\n","=\u003e set norm(stage0.patch_embed.norm.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm1.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm1.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm2.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm2.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.mlp.fc2.bias) wd to 0\n","=\u003e set bias(stage1.patch_embed.proj.bias) wd to 0\n","=\u003e set norm(stage1.patch_embed.norm.weight) wd to 0\n","=\u003e set norm(stage1.patch_embed.norm.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm1.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm1.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm2.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm2.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm1.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm1.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm2.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm2.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.mlp.fc2.bias) wd to 0\n","=\u003e set stage2.cls_token wd to 0\n","=\u003e set bias(stage2.patch_embed.proj.bias) wd to 0\n","=\u003e set norm(stage2.patch_embed.norm.weight) wd to 0\n","=\u003e set norm(stage2.patch_embed.norm.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.mlp.fc2.bias) wd to 0\n","=\u003e set norm(norm.weight) wd to 0\n","=\u003e set norm(norm.bias) wd to 0\n","=\u003e set bias(head.bias) wd to 0\n","2022-05-18 13:16:25,565:[P:2305]:Rank[0/1] =\u003e use timm loader for training\n","2022-05-18 13:16:31,211:[P:2305]:Rank[0/1] =\u003e start training\n","2022-05-18 13:16:31,212:[P:2305]:Rank[0/1] =\u003e Epoch[0]: epoch start\n","2022-05-18 13:16:31,213:[P:2305]:Rank[0/1] =\u003e Epoch[0]: train start\n","2022-05-18 13:16:31,214:[P:2305]:Rank[0/1] =\u003e switch to train mode\n","2022-05-18 13:16:48,034:[P:2305]:Rank[0/1] =\u003e Epoch[0][0/40031]: Time 16.817s (16.817s)\tSpeed 1.9 samples/s\tData 16.376s (16.376s)\tLoss 6.94897 (6.94897)\tAccuracy@1 0.000 (0.000)\tAccuracy@5 0.000 (0.000)\t\n","2022-05-18 13:45:52,576:[P:2305]:Rank[0/1] =\u003e Epoch[0][500/40031]: Time 0.143s (3.516s)\tSpeed 223.4 samples/s\tData 0.001s (3.356s)\tLoss 6.96867 (6.97497)\tAccuracy@1 0.000 (0.081)\tAccuracy@5 0.000 (0.536)\t\n","2022-05-18 14:14:47,706:[P:2305]:Rank[0/1] =\u003e Epoch[0][1000/40031]: Time 0.159s (3.493s)\tSpeed 201.4 samples/s\tData 0.001s (3.331s)\tLoss 6.79791 (6.97052)\tAccuracy@1 3.125 (0.112)\tAccuracy@5 3.125 (0.515)\t\n","2022-05-18 14:43:18,092:[P:2305]:Rank[0/1] =\u003e Epoch[0][1500/40031]: Time 0.163s (3.469s)\tSpeed 196.1 samples/s\tData 0.001s (3.307s)\tLoss 6.97461 (6.96446)\tAccuracy@1 0.000 (0.117)\tAccuracy@5 0.000 (0.516)\t\n","2022-05-18 15:11:48,763:[P:2305]:Rank[0/1] =\u003e Epoch[0][2000/40031]: Time 0.158s (3.457s)\tSpeed 201.9 samples/s\tData 0.001s (3.294s)\tLoss 6.90751 (6.95902)\tAccuracy@1 0.000 (0.117)\tAccuracy@5 0.000 (0.545)\t\n","2022-05-18 15:40:47,540:[P:2305]:Rank[0/1] =\u003e Epoch[0][2500/40031]: Time 0.153s (3.461s)\tSpeed 208.8 samples/s\tData 0.001s (3.298s)\tLoss 7.07811 (6.95600)\tAccuracy@1 0.000 (0.112)\tAccuracy@5 0.000 (0.546)\t\n","2022-05-18 16:09:31,259:[P:2305]:Rank[0/1] =\u003e Epoch[0][3000/40031]: Time 0.162s (3.459s)\tSpeed 197.5 samples/s\tData 0.002s (3.296s)\tLoss 6.94235 (6.95257)\tAccuracy@1 0.000 (0.121)\tAccuracy@5 0.000 (0.580)\t\n","2022-05-18 16:38:27,392:[P:2305]:Rank[0/1] =\u003e Epoch[0][3500/40031]: Time 0.147s (3.461s)\tSpeed 217.9 samples/s\tData 0.001s (3.298s)\tLoss 6.87125 (6.94933)\tAccuracy@1 0.000 (0.121)\tAccuracy@5 0.000 (0.593)\t\n","2022-05-18 17:08:13,435:[P:2305]:Rank[0/1] =\u003e Epoch[0][4000/40031]: Time 4.474s (3.475s)\tSpeed 7.2 samples/s\tData 4.309s (3.312s)\tLoss 6.97054 (6.94665)\tAccuracy@1 3.125 (0.129)\tAccuracy@5 3.125 (0.605)\t\n","2022-05-18 17:37:49,448:[P:2305]:Rank[0/1] =\u003e Epoch[0][4500/40031]: Time 19.190s (3.483s)\tSpeed 1.7 samples/s\tData 19.022s (3.320s)\tLoss 6.93608 (6.94402)\tAccuracy@1 0.000 (0.132)\tAccuracy@5 0.000 (0.619)\t\n","2022-05-18 18:07:07,999:[P:2305]:Rank[0/1] =\u003e Epoch[0][5000/40031]: Time 21.433s (3.487s)\tSpeed 1.5 samples/s\tData 21.259s (3.323s)\tLoss 6.95590 (6.94189)\tAccuracy@1 0.000 (0.138)\tAccuracy@5 0.000 (0.644)\t\n","2022-05-18 18:38:27,467:[P:2305]:Rank[0/1] =\u003e Epoch[0][5500/40031]: Time 0.264s (3.511s)\tSpeed 121.2 samples/s\tData 0.001s (3.347s)\tLoss 6.89407 (6.93957)\tAccuracy@1 0.000 (0.143)\tAccuracy@5 0.000 (0.672)\t\n","2022-05-18 19:10:17,876:[P:2305]:Rank[0/1] =\u003e Epoch[0][6000/40031]: Time 0.149s (3.537s)\tSpeed 215.3 samples/s\tData 0.001s (3.372s)\tLoss 6.96230 (6.93723)\tAccuracy@1 0.000 (0.148)\tAccuracy@5 0.000 (0.694)\t\n","2022-05-18 19:43:02,979:[P:2305]:Rank[0/1] =\u003e Epoch[0][6500/40031]: Time 0.185s (3.567s)\tSpeed 173.4 samples/s\tData 0.001s (3.402s)\tLoss 6.94940 (6.93526)\tAccuracy@1 0.000 (0.150)\tAccuracy@5 0.000 (0.724)\t\n","2022-05-18 20:17:16,781:[P:2305]:Rank[0/1] =\u003e Epoch[0][7000/40031]: Time 24.076s (3.606s)\tSpeed 1.3 samples/s\tData 23.911s (3.440s)\tLoss 6.87734 (6.93339)\tAccuracy@1 0.000 (0.159)\tAccuracy@5 0.000 (0.753)\t\n","2022-05-18 20:51:21,893:[P:2305]:Rank[0/1] =\u003e Epoch[0][7500/40031]: Time 0.168s (3.638s)\tSpeed 190.1 samples/s\tData 0.001s (3.472s)\tLoss 6.89824 (6.93171)\tAccuracy@1 0.000 (0.165)\tAccuracy@5 0.000 (0.770)\t\n","2022-05-18 21:25:31,733:[P:2305]:Rank[0/1] =\u003e Epoch[0][8000/40031]: Time 0.162s (3.667s)\tSpeed 197.0 samples/s\tData 0.001s (3.500s)\tLoss 6.94468 (6.93033)\tAccuracy@1 0.000 (0.173)\tAccuracy@5 0.000 (0.785)\t\n","2022-05-18 21:58:11,927:[P:2305]:Rank[0/1] =\u003e Epoch[0][8500/40031]: Time 0.170s (3.682s)\tSpeed 188.7 samples/s\tData 0.001s (3.515s)\tLoss 6.88128 (6.92865)\tAccuracy@1 3.125 (0.176)\tAccuracy@5 3.125 (0.805)\t\n","2022-05-18 22:30:34,139:[P:2305]:Rank[0/1] =\u003e Epoch[0][9000/40031]: Time 7.353s (3.693s)\tSpeed 4.4 samples/s\tData 7.192s (3.526s)\tLoss 6.91463 (6.92705)\tAccuracy@1 0.000 (0.179)\tAccuracy@5 0.000 (0.826)\t\n","2022-05-18 23:02:50,282:[P:2305]:Rank[0/1] =\u003e Epoch[0][9500/40031]: Time 13.429s (3.703s)\tSpeed 2.4 samples/s\tData 13.272s (3.535s)\tLoss 6.88990 (6.92569)\tAccuracy@1 0.000 (0.187)\tAccuracy@5 0.000 (0.846)\t\n","2022-05-18 23:35:31,351:[P:2305]:Rank[0/1] =\u003e Epoch[0][10000/40031]: Time 0.158s (3.714s)\tSpeed 202.6 samples/s\tData 0.001s (3.546s)\tLoss 6.94330 (6.92434)\tAccuracy@1 0.000 (0.189)\tAccuracy@5 3.125 (0.856)\t\n","2022-05-19 00:09:03,197:[P:2305]:Rank[0/1] =\u003e Epoch[0][10500/40031]: Time 0.179s (3.728s)\tSpeed 179.1 samples/s\tData 0.001s (3.561s)\tLoss 6.85157 (6.92295)\tAccuracy@1 0.000 (0.192)\tAccuracy@5 3.125 (0.869)\t\n"]}],"source":["!bash run.sh -g 1 -t train --cfg experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"StwqoSjvNLJk"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bx_kGI9JNLB-"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7rNXOb6NKzS"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5871169,"status":"ok","timestamp":1652856601817,"user":{"displayName":"최새미","userId":"13431835325743060622"},"user_tz":-540},"id":"diic1z7DLvit","outputId":"3cd1aa70-b88e-4966-afc4-6cc5ee0119e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["job type: train\n","rank: 0\n","node count: 1\n","master addr: 127.0.0.1\n","=\u003e merge config from experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml\n","=\u003e creating OUTPUT ...\n","=\u003e creating OUTPUT/imagenet/cvt-13-224x224-b32-e3 ...\n","=\u003e setup logger ...\n","2022-05-18 05:12:16,979:[P:1312]:Rank[0/1] =\u003e collecting env info (might take some time)\n","2022-05-18 05:12:19,123:[P:1312]:Rank[0/1] \n","PyTorch version: 1.7.1\n","Is debug build: False\n","CUDA used to build PyTorch: 10.2\n","ROCM used to build PyTorch: N/A\n","\n","OS: Ubuntu 18.04.5 LTS (x86_64)\n","GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n","CMake version: version 3.22.4\n","\n","Python version: 3.7 (64-bit runtime)\n","Is CUDA available: True\n","CUDA runtime version: Could not collect\n","GPU models and configuration: GPU 0: Tesla V100-SXM2-16GB\n","Nvidia driver version: 460.32.03\n","cuDNN version: Probably one of the following:\n","/usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n","/usr/lib/x86_64-linux-gnu/libcudnn.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.0.5\n","HIP runtime version: N/A\n","MIOpen runtime version: N/A\n","\n","Versions of relevant libraries:\n","[pip3] numpy==1.19.3\n","[pip3] torch==1.7.1\n","[pip3] torchaudio==0.7.2\n","[pip3] torchsummary==1.5.1\n","[pip3] torchtext==0.12.0\n","[pip3] torchvision==0.8.2\n","[conda] Could not collect\n","2022-05-18 05:12:19,124:[P:1312]:Rank[0/1] Namespace(cfg='experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml', distributed=False, local_rank=0, num_gpus=1, opts=[], port=9000)\n","2022-05-18 05:12:19,124:[P:1312]:Rank[0/1] AMP:\n","  ENABLED: True\n","  MEMORY_FORMAT: nchw\n","AUG:\n","  COLOR_JITTER: [0.4, 0.4, 0.4, 0.1, 0.0]\n","  DROPBLOCK_BLOCK_SIZE: 7\n","  DROPBLOCK_KEEP_PROB: 1.0\n","  DROPBLOCK_LAYERS: [3, 4]\n","  GAUSSIAN_BLUR: 0.0\n","  GRAY_SCALE: 0.0\n","  INTERPOLATION: 2\n","  MIXCUT: 1.0\n","  MIXCUT_AND_MIXUP: False\n","  MIXCUT_MINMAX: []\n","  MIXUP: 0.8\n","  MIXUP_MODE: batch\n","  MIXUP_PROB: 1.0\n","  MIXUP_SWITCH_PROB: 0.5\n","  RATIO: (0.75, 1.3333333333333333)\n","  SCALE: (0.08, 1.0)\n","  TIMM_AUG:\n","    AUTO_AUGMENT: rand-m9-mstd0.5-inc1\n","    COLOR_JITTER: 0.4\n","    HFLIP: 0.5\n","    INTERPOLATION: bicubic\n","    RE_COUNT: 1\n","    RE_MODE: pixel\n","    RE_PROB: 0.25\n","    RE_SPLIT: False\n","    USE_LOADER: True\n","    USE_TRANSFORM: False\n","    VFLIP: 0.0\n","BASE: ['']\n","CUDNN:\n","  BENCHMARK: True\n","  DETERMINISTIC: False\n","  ENABLED: True\n","DATASET:\n","  DATASET: imagenet\n","  DATA_FORMAT: jpg\n","  LABELMAP: \n","  ROOT: DATASET/imagenet/\n","  SAMPLER: default\n","  TARGET_SIZE: -1\n","  TEST_SET: val\n","  TEST_TSV_LIST: []\n","  TRAIN_SET: train\n","  TRAIN_TSV_LIST: []\n","DATA_DIR: \n","DEBUG:\n","  DEBUG: False\n","DIST_BACKEND: nccl\n","FINETUNE:\n","  BASE_LR: 0.003\n","  BATCH_SIZE: 512\n","  EVAL_EVERY: 3000\n","  FINETUNE: False\n","  FROZEN_LAYERS: []\n","  LR_SCHEDULER:\n","    DECAY_TYPE: step\n","  TRAIN_MODE: True\n","  USE_TRAIN_AUG: False\n","GPUS: (0,)\n","INPUT:\n","  MEAN: [0.485, 0.456, 0.406]\n","  STD: [0.229, 0.224, 0.225]\n","LOSS:\n","  LABEL_SMOOTHING: 0.1\n","  LOSS: softmax\n","MODEL:\n","  INIT_WEIGHTS: True\n","  NAME: cls_cvt\n","  NUM_CLASSES: 1000\n","  PRETRAINED: \n","  PRETRAINED_LAYERS: ['*']\n","  SPEC:\n","    ATTN_DROP_RATE: [0.0, 0.0, 0.0]\n","    CLS_TOKEN: [False, False, True]\n","    DEPTH: [1, 2, 10]\n","    DIM_EMBED: [64, 192, 384]\n","    DROP_PATH_RATE: [0.0, 0.0, 0.1]\n","    DROP_RATE: [0.0, 0.0, 0.0]\n","    INIT: trunc_norm\n","    KERNEL_QKV: [3, 3, 3]\n","    MLP_RATIO: [4.0, 4.0, 4.0]\n","    NUM_HEADS: [1, 3, 6]\n","    NUM_STAGES: 3\n","    PADDING_KV: [1, 1, 1]\n","    PADDING_Q: [1, 1, 1]\n","    PATCH_PADDING: [2, 1, 1]\n","    PATCH_SIZE: [7, 3, 3]\n","    PATCH_STRIDE: [4, 2, 2]\n","    POS_EMBED: [False, False, False]\n","    QKV_BIAS: [True, True, True]\n","    QKV_PROJ_METHOD: ['dw_bn', 'dw_bn', 'dw_bn']\n","    STRIDE_KV: [2, 2, 2]\n","    STRIDE_Q: [1, 1, 1]\n","MODEL_SUMMARY: False\n","MULTIPROCESSING_DISTRIBUTED: True\n","NAME: cvt-13-224x224-b32-e3\n","OUTPUT_DIR: OUTPUT/\n","PIN_MEMORY: True\n","PRINT_FREQ: 500\n","RANK: 0\n","TEST:\n","  BATCH_SIZE_PER_GPU: 32\n","  CENTER_CROP: True\n","  IMAGE_SIZE: [224, 224]\n","  INTERPOLATION: 3\n","  MODEL_FILE: \n","  REAL_LABELS: False\n","  VALID_LABELS: \n","TRAIN:\n","  AUTO_RESUME: True\n","  BATCH_SIZE_PER_GPU: 64\n","  BEGIN_EPOCH: 0\n","  CHECKPOINT: \n","  CLIP_GRAD_NORM: 0.0\n","  DETECT_ANOMALY: False\n","  END_EPOCH: 3\n","  EVAL_BEGIN_EPOCH: 0\n","  GAMMA1: 0.99\n","  GAMMA2: 0.0\n","  IMAGE_SIZE: [224, 224]\n","  LR: 0.00025\n","  LR_SCHEDULER:\n","    ARGS:\n","      cooldown_epochs: 10\n","      decay_rate: 0.1\n","      epochs: 3\n","      min_lr: 1e-05\n","      sched: cosine\n","      warmup_epochs: 5\n","      warmup_lr: 1e-06\n","    METHOD: timm\n","  MOMENTUM: 0.9\n","  NESTEROV: True\n","  OPTIMIZER: adamW\n","  OPTIMIZER_ARGS:\n","    \n","  SAVE_ALL_MODELS: False\n","  SCALE_LR: True\n","  SHUFFLE: True\n","  WD: 0.05\n","  WITHOUT_WD_LIST: ['bn', 'bias', 'ln']\n","VERBOSE: True\n","WORKERS: 6\n","2022-05-18 05:12:19,125:[P:1312]:Rank[0/1] =\u003e using 1 GPUs\n","2022-05-18 05:12:19,125:[P:1312]:Rank[0/1] =\u003e saving config into: OUTPUT/imagenet/cvt-13-224x224-b32-e3/config.yaml\n","2022-05-18 05:12:19,171:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,210:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,210:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,211:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,211:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,211:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,211:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,212:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,212:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,212:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,213:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,213:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,231:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,232:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,232:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,232:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,233:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,233:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,234:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,234:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,234:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,236:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,236:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,237:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,238:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,238:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,239:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,239:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,239:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,240:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,240:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,241:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,241:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,243:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,243:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,244:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,412:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,414:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,414:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,416:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,416:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,417:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,418:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,419:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,420:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,424:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,425:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,429:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,430:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,431:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,432:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,433:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,433:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,435:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,435:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,436:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,437:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,442:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,442:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,447:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,448:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,450:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,450:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,453:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,453:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,454:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,455:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,456:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,457:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,461:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,462:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,466:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,467:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,469:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,469:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,470:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,471:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,472:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,473:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,474:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,474:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,479:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,479:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,484:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,485:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,486:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,486:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,488:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,488:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,489:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,490:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,491:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,491:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,496:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,496:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,501:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,502:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,503:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,503:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,505:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,505:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,507:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,507:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,508:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,509:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,514:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,514:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,518:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,519:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,520:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,521:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,522:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,522:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,524:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,524:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,525:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,526:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,530:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,531:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,536:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,536:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,537:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,538:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,539:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,539:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,541:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,541:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,542:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,543:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,547:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,548:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,553:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,554:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,556:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,556:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,557:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,558:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,559:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,559:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,561:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,561:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,566:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,567:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,571:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,572:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,574:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,577:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,578:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,579:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,581:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,581:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,583:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,584:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,592:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:19,592:[P:1312]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-18 05:12:19,597:[P:1312]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-18 05:12:25,499:[P:1312]:Rank[0/1] =\u003e ConvolutionalVisionTransformer(\n","  (stage0): VisionTransformer(\n","    (patch_embed): ConvEmbed(\n","      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n","      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (blocks): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=64, out_features=64, bias=True)\n","          (proj_k): Linear(in_features=64, out_features=64, bias=True)\n","          (proj_v): Linear(in_features=64, out_features=64, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=64, out_features=64, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=64, out_features=256, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=256, out_features=64, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (stage1): VisionTransformer(\n","    (patch_embed): ConvEmbed(\n","      (proj): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (blocks): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_k): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_v): Linear(in_features=192, out_features=192, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=192, out_features=768, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=768, out_features=192, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_k): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_v): Linear(in_features=192, out_features=192, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=192, out_features=768, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=768, out_features=192, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (stage2): VisionTransformer(\n","    (patch_embed): ConvEmbed(\n","      (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (blocks): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","  (head): Linear(in_features=384, out_features=1000, bias=True)\n",")\n","2022-05-18 05:12:25,587:[P:1312]:Rank[0/1] Trainable Model Total Parameter: \t20.0M\n","=\u003e set bias(stage0.patch_embed.proj.bias) wd to 0\n","=\u003e set norm(stage0.patch_embed.norm.weight) wd to 0\n","=\u003e set norm(stage0.patch_embed.norm.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm1.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm1.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm2.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm2.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.mlp.fc2.bias) wd to 0\n","=\u003e set bias(stage1.patch_embed.proj.bias) wd to 0\n","=\u003e set norm(stage1.patch_embed.norm.weight) wd to 0\n","=\u003e set norm(stage1.patch_embed.norm.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm1.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm1.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm2.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm2.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm1.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm1.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm2.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm2.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.mlp.fc2.bias) wd to 0\n","=\u003e set stage2.cls_token wd to 0\n","=\u003e set bias(stage2.patch_embed.proj.bias) wd to 0\n","=\u003e set norm(stage2.patch_embed.norm.weight) wd to 0\n","=\u003e set norm(stage2.patch_embed.norm.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.mlp.fc2.bias) wd to 0\n","=\u003e set norm(norm.weight) wd to 0\n","=\u003e set norm(norm.bias) wd to 0\n","=\u003e set bias(head.bias) wd to 0\n","2022-05-18 05:14:27,630:[P:1312]:Rank[0/1] =\u003e use timm loader for training\n","2022-05-18 05:14:32,739:[P:1312]:Rank[0/1] =\u003e start training\n","2022-05-18 05:14:32,740:[P:1312]:Rank[0/1] =\u003e Epoch[0]: epoch start\n","2022-05-18 05:14:32,740:[P:1312]:Rank[0/1] =\u003e Epoch[0]: train start\n","2022-05-18 05:14:32,740:[P:1312]:Rank[0/1] =\u003e switch to train mode\n","2022-05-18 05:14:57,864:[P:1312]:Rank[0/1] =\u003e Epoch[0][0/20019]: Time 25.119s (25.119s)\tSpeed 2.5 samples/s\tData 24.537s (24.537s)\tLoss 7.05316 (7.05316)\tAccuracy@1 0.000 (0.000)\tAccuracy@5 0.000 (0.000)\t\n","2022-05-18 05:53:05,089:[P:1312]:Rank[0/1] =\u003e Epoch[0][500/20019]: Time 0.215s (4.615s)\tSpeed 298.3 samples/s\tData 0.001s (4.402s)\tLoss 6.94956 (6.97265)\tAccuracy@1 0.000 (0.109)\tAccuracy@5 1.562 (0.533)\t\n","2022-05-18 06:31:59,268:[P:1312]:Rank[0/1] =\u003e Epoch[0][1000/20019]: Time 0.208s (4.642s)\tSpeed 308.1 samples/s\tData 0.001s (4.428s)\tLoss 7.01365 (6.96341)\tAccuracy@1 0.000 (0.100)\tAccuracy@5 0.000 (0.568)\t\n","Traceback (most recent call last):\n","  File \"tools/train.py\", line 212, in \u003cmodule\u003e\n","    main()\n","  File \"tools/train.py\", line 139, in main\n","    scaler=scaler)\n","  File \"/content/drive/MyDrive/FinalProject/CvT-main/tools/../lib/core/function.py\", line 36, in train_one_epoch\n","    for i, (x, y) in enumerate(train_loader):\n","  File \"/root/.local/lib/python3.7/site-packages/timm/data/loader.py\", line 82, in __iter__\n","    for next_input, next_target in self.loader:\n","  File \"/root/.local/lib/python3.7/site-packages/timm/data/loader.py\", line 242, in __iter__\n","    yield next(self.iterator)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1085, in _next_data\n","    return self._process_data(data)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1111, in _process_data\n","    data.reraise()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 428, in reraise\n","    raise self.exc_type(msg)\n","FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 4.\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n","    data = fetcher.fetch(index)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in \u003clistcomp\u003e\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\", line 151, in __getitem__\n","    sample = self.loader(path)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\", line 188, in default_loader\n","    return pil_loader(path)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\", line 168, in pil_loader\n","    with open(path, 'rb') as f:\n","FileNotFoundError: [Errno 2] No such file or directory: 'DATASET/imagenet/train/n01950731/n02093428/n02093428_10007.JPEG'\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 260, in \u003cmodule\u003e\n","    main()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 256, in main\n","    cmd=cmd)\n","subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'tools/train.py', '--local_rank=0', '--cfg', 'experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml']' returned non-zero exit status 1.\n"]}],"source":["!bash run.sh -g 1 -t train --cfg experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30818090,"status":"ok","timestamp":1652807114694,"user":{"displayName":"최새미","userId":"13431835325743060622"},"user_tz":-540},"id":"okzgyy54RmGc","outputId":"dc953e7b-ea1f-491d-d453-d77996629f11"},"outputs":[{"name":"stdout","output_type":"stream","text":["job type: train\n","rank: 0\n","node count: 1\n","master addr: 127.0.0.1\n","=\u003e merge config from experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml\n","=\u003e creating OUTPUT ...\n","=\u003e creating OUTPUT/imagenet/cvt-13-224x224-b32-e3 ...\n","=\u003e setup logger ...\n","2022-05-17 08:31:55,665:[P:402]:Rank[0/1] =\u003e collecting env info (might take some time)\n","2022-05-17 08:31:57,581:[P:402]:Rank[0/1] \n","PyTorch version: 1.7.1\n","Is debug build: False\n","CUDA used to build PyTorch: 10.2\n","ROCM used to build PyTorch: N/A\n","\n","OS: Ubuntu 18.04.5 LTS (x86_64)\n","GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n","CMake version: version 3.22.4\n","\n","Python version: 3.7 (64-bit runtime)\n","Is CUDA available: True\n","CUDA runtime version: Could not collect\n","GPU models and configuration: GPU 0: Tesla T4\n","Nvidia driver version: 460.32.03\n","cuDNN version: Probably one of the following:\n","/usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n","/usr/lib/x86_64-linux-gnu/libcudnn.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.0.5\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.0.5\n","HIP runtime version: N/A\n","MIOpen runtime version: N/A\n","\n","Versions of relevant libraries:\n","[pip3] numpy==1.19.3\n","[pip3] torch==1.7.1\n","[pip3] torchaudio==0.7.2\n","[pip3] torchsummary==1.5.1\n","[pip3] torchtext==0.12.0\n","[pip3] torchvision==0.8.2\n","[conda] Could not collect\n","2022-05-17 08:31:57,582:[P:402]:Rank[0/1] Namespace(cfg='experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml', distributed=False, local_rank=0, num_gpus=1, opts=[], port=9000)\n","2022-05-17 08:31:57,582:[P:402]:Rank[0/1] AMP:\n","  ENABLED: True\n","  MEMORY_FORMAT: nchw\n","AUG:\n","  COLOR_JITTER: [0.4, 0.4, 0.4, 0.1, 0.0]\n","  DROPBLOCK_BLOCK_SIZE: 7\n","  DROPBLOCK_KEEP_PROB: 1.0\n","  DROPBLOCK_LAYERS: [3, 4]\n","  GAUSSIAN_BLUR: 0.0\n","  GRAY_SCALE: 0.0\n","  INTERPOLATION: 2\n","  MIXCUT: 1.0\n","  MIXCUT_AND_MIXUP: False\n","  MIXCUT_MINMAX: []\n","  MIXUP: 0.8\n","  MIXUP_MODE: batch\n","  MIXUP_PROB: 1.0\n","  MIXUP_SWITCH_PROB: 0.5\n","  RATIO: (0.75, 1.3333333333333333)\n","  SCALE: (0.08, 1.0)\n","  TIMM_AUG:\n","    AUTO_AUGMENT: rand-m9-mstd0.5-inc1\n","    COLOR_JITTER: 0.4\n","    HFLIP: 0.5\n","    INTERPOLATION: bicubic\n","    RE_COUNT: 1\n","    RE_MODE: pixel\n","    RE_PROB: 0.25\n","    RE_SPLIT: False\n","    USE_LOADER: True\n","    USE_TRANSFORM: False\n","    VFLIP: 0.0\n","BASE: ['']\n","CUDNN:\n","  BENCHMARK: True\n","  DETERMINISTIC: False\n","  ENABLED: True\n","DATASET:\n","  DATASET: imagenet\n","  DATA_FORMAT: jpg\n","  LABELMAP: \n","  ROOT: DATASET/imagenet/\n","  SAMPLER: default\n","  TARGET_SIZE: -1\n","  TEST_SET: val\n","  TEST_TSV_LIST: []\n","  TRAIN_SET: train\n","  TRAIN_TSV_LIST: []\n","DATA_DIR: \n","DEBUG:\n","  DEBUG: False\n","DIST_BACKEND: nccl\n","FINETUNE:\n","  BASE_LR: 0.003\n","  BATCH_SIZE: 512\n","  EVAL_EVERY: 3000\n","  FINETUNE: False\n","  FROZEN_LAYERS: []\n","  LR_SCHEDULER:\n","    DECAY_TYPE: step\n","  TRAIN_MODE: True\n","  USE_TRAIN_AUG: False\n","GPUS: (0,)\n","INPUT:\n","  MEAN: [0.485, 0.456, 0.406]\n","  STD: [0.229, 0.224, 0.225]\n","LOSS:\n","  LABEL_SMOOTHING: 0.1\n","  LOSS: softmax\n","MODEL:\n","  INIT_WEIGHTS: True\n","  NAME: cls_cvt\n","  NUM_CLASSES: 1000\n","  PRETRAINED: \n","  PRETRAINED_LAYERS: ['*']\n","  SPEC:\n","    ATTN_DROP_RATE: [0.0, 0.0, 0.0]\n","    CLS_TOKEN: [False, False, True]\n","    DEPTH: [1, 2, 10]\n","    DIM_EMBED: [64, 192, 384]\n","    DROP_PATH_RATE: [0.0, 0.0, 0.1]\n","    DROP_RATE: [0.0, 0.0, 0.0]\n","    INIT: trunc_norm\n","    KERNEL_QKV: [3, 3, 3]\n","    MLP_RATIO: [4.0, 4.0, 4.0]\n","    NUM_HEADS: [1, 3, 6]\n","    NUM_STAGES: 3\n","    PADDING_KV: [1, 1, 1]\n","    PADDING_Q: [1, 1, 1]\n","    PATCH_PADDING: [2, 1, 1]\n","    PATCH_SIZE: [7, 3, 3]\n","    PATCH_STRIDE: [4, 2, 2]\n","    POS_EMBED: [False, False, False]\n","    QKV_BIAS: [True, True, True]\n","    QKV_PROJ_METHOD: ['dw_bn', 'dw_bn', 'dw_bn']\n","    STRIDE_KV: [2, 2, 2]\n","    STRIDE_Q: [1, 1, 1]\n","MODEL_SUMMARY: False\n","MULTIPROCESSING_DISTRIBUTED: True\n","NAME: cvt-13-224x224-b32-e3\n","OUTPUT_DIR: OUTPUT/\n","PIN_MEMORY: True\n","PRINT_FREQ: 500\n","RANK: 0\n","TEST:\n","  BATCH_SIZE_PER_GPU: 32\n","  CENTER_CROP: True\n","  IMAGE_SIZE: [224, 224]\n","  INTERPOLATION: 3\n","  MODEL_FILE: \n","  REAL_LABELS: False\n","  VALID_LABELS: \n","TRAIN:\n","  AUTO_RESUME: True\n","  BATCH_SIZE_PER_GPU: 32\n","  BEGIN_EPOCH: 0\n","  CHECKPOINT: \n","  CLIP_GRAD_NORM: 0.0\n","  DETECT_ANOMALY: False\n","  END_EPOCH: 3\n","  EVAL_BEGIN_EPOCH: 0\n","  GAMMA1: 0.99\n","  GAMMA2: 0.0\n","  IMAGE_SIZE: [224, 224]\n","  LR: 0.00025\n","  LR_SCHEDULER:\n","    ARGS:\n","      cooldown_epochs: 10\n","      decay_rate: 0.1\n","      epochs: 3\n","      min_lr: 1e-05\n","      sched: cosine\n","      warmup_epochs: 5\n","      warmup_lr: 1e-06\n","    METHOD: timm\n","  MOMENTUM: 0.9\n","  NESTEROV: True\n","  OPTIMIZER: adamW\n","  OPTIMIZER_ARGS:\n","    \n","  SAVE_ALL_MODELS: False\n","  SCALE_LR: True\n","  SHUFFLE: True\n","  WD: 0.05\n","  WITHOUT_WD_LIST: ['bn', 'bias', 'ln']\n","VERBOSE: True\n","WORKERS: 6\n","2022-05-17 08:31:57,583:[P:402]:Rank[0/1] =\u003e using 1 GPUs\n","2022-05-17 08:31:57,583:[P:402]:Rank[0/1] =\u003e saving config into: OUTPUT/imagenet/cvt-13-224x224-b32-e3/config.yaml\n","2022-05-17 08:31:57,896:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,897:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,897:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,897:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,898:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,898:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,898:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,899:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,899:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,899:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,899:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,900:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,911:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,912:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,912:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,913:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,913:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,914:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,914:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,915:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,915:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,917:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,917:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,919:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,919:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,920:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,920:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,920:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,920:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,921:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,921:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,922:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,922:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,923:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:57,924:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:57,925:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,080:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,082:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,082:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,083:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,084:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,085:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,085:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,087:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,087:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,092:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,093:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,098:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,099:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,100:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,100:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,102:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,102:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,103:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,104:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,105:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,106:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,111:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,111:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,117:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,117:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,119:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,119:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,121:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,121:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,122:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,123:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,124:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,124:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,129:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,130:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,135:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,135:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,137:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,137:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,139:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,139:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,140:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,141:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,142:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,142:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,147:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,148:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,153:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,153:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,155:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,155:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,156:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,157:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,158:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,159:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,160:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,160:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,165:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,165:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,171:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,171:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,173:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,173:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,175:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,175:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,176:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,177:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,178:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,179:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,183:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,184:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,189:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,189:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,191:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,191:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,193:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,193:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,195:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,195:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,196:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,197:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,205:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,206:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,211:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,211:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,213:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,213:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,214:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,215:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,216:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,217:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,218:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,218:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,223:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,224:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,229:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,229:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,231:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,231:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,232:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,233:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,234:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,234:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,236:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,236:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,241:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,241:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,246:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,247:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,248:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,249:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,250:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,250:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,252:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,252:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,254:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,254:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,259:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:31:58,260:[P:402]:Rank[0/1] =\u003e init weight of Linear from trunc norm\n","2022-05-17 08:31:58,265:[P:402]:Rank[0/1] =\u003e init bias of Linear to zeros\n","2022-05-17 08:32:01,962:[P:402]:Rank[0/1] =\u003e ConvolutionalVisionTransformer(\n","  (stage0): VisionTransformer(\n","    (patch_embed): ConvEmbed(\n","      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n","      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (blocks): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n","            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=64, out_features=64, bias=True)\n","          (proj_k): Linear(in_features=64, out_features=64, bias=True)\n","          (proj_v): Linear(in_features=64, out_features=64, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=64, out_features=64, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=64, out_features=256, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=256, out_features=64, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (stage1): VisionTransformer(\n","    (patch_embed): ConvEmbed(\n","      (proj): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (blocks): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_k): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_v): Linear(in_features=192, out_features=192, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=192, out_features=768, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=768, out_features=192, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_k): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_v): Linear(in_features=192, out_features=192, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=192, out_features=192, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=192, out_features=768, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=768, out_features=192, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (stage2): VisionTransformer(\n","    (patch_embed): ConvEmbed(\n","      (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (blocks): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (conv_proj_q): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_k): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (conv_proj_v): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n","            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (rearrage): Rearrange('b c h w -\u003e b (h w) c')\n","          )\n","          (proj_q): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_k): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_v): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=384, out_features=384, bias=True)\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","          (act): QuickGELU()\n","          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n","  (head): Linear(in_features=384, out_features=1000, bias=True)\n",")\n","2022-05-17 08:32:02,033:[P:402]:Rank[0/1] Trainable Model Total Parameter: \t20.0M\n","=\u003e set bias(stage0.patch_embed.proj.bias) wd to 0\n","=\u003e set norm(stage0.patch_embed.norm.weight) wd to 0\n","=\u003e set norm(stage0.patch_embed.norm.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm1.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm1.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.attn.proj.bias) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm2.weight) wd to 0\n","=\u003e set norm(stage0.blocks.0.norm2.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage0.blocks.0.mlp.fc2.bias) wd to 0\n","=\u003e set bias(stage1.patch_embed.proj.bias) wd to 0\n","=\u003e set norm(stage1.patch_embed.norm.weight) wd to 0\n","=\u003e set norm(stage1.patch_embed.norm.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm1.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm1.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.attn.proj.bias) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm2.weight) wd to 0\n","=\u003e set norm(stage1.blocks.0.norm2.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage1.blocks.0.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm1.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm1.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.attn.proj.bias) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm2.weight) wd to 0\n","=\u003e set norm(stage1.blocks.1.norm2.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage1.blocks.1.mlp.fc2.bias) wd to 0\n","=\u003e set stage2.cls_token wd to 0\n","=\u003e set bias(stage2.patch_embed.proj.bias) wd to 0\n","=\u003e set norm(stage2.patch_embed.norm.weight) wd to 0\n","=\u003e set norm(stage2.patch_embed.norm.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.0.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.0.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.1.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.1.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.2.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.2.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.3.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.3.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.4.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.4.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.5.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.5.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.6.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.6.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.7.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.7.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.8.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.8.mlp.fc2.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm1.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm1.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_q.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_q.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_k.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_k.bn.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_v.bn.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.attn.conv_proj_v.bn.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj_q.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj_k.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj_v.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.attn.proj.bias) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm2.weight) wd to 0\n","=\u003e set norm(stage2.blocks.9.norm2.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.mlp.fc1.bias) wd to 0\n","=\u003e set bias(stage2.blocks.9.mlp.fc2.bias) wd to 0\n","=\u003e set norm(norm.weight) wd to 0\n","=\u003e set norm(norm.bias) wd to 0\n","=\u003e set bias(head.bias) wd to 0\n","2022-05-17 09:00:55,835:[P:402]:Rank[0/1] =\u003e use timm loader for training\n","2022-05-17 09:02:46,729:[P:402]:Rank[0/1] =\u003e start training\n","2022-05-17 09:02:46,729:[P:402]:Rank[0/1] =\u003e Epoch[0]: epoch start\n","2022-05-17 09:02:46,729:[P:402]:Rank[0/1] =\u003e Epoch[0]: train start\n","2022-05-17 09:02:46,729:[P:402]:Rank[0/1] =\u003e switch to train mode\n","2022-05-17 09:02:47,443:[P:402]:Rank[0/1] =\u003e Epoch[0][0/40038]: Time 0.711s (0.711s)\tSpeed 45.0 samples/s\tData 0.028s (0.028s)\tLoss 7.03319 (7.03319)\tAccuracy@1 0.000 (0.000)\tAccuracy@5 0.000 (0.000)\t\n","2022-05-17 09:17:03,152:[P:402]:Rank[0/1] =\u003e Epoch[0][500/40038]: Time 0.271s (1.709s)\tSpeed 118.0 samples/s\tData 0.001s (1.415s)\tLoss 6.99553 (6.97337)\tAccuracy@1 0.000 (0.094)\tAccuracy@5 0.000 (0.493)\t\n","2022-05-17 09:31:14,371:[P:402]:Rank[0/1] =\u003e Epoch[0][1000/40038]: Time 0.286s (1.706s)\tSpeed 112.0 samples/s\tData 0.001s (1.409s)\tLoss 6.99157 (6.96715)\tAccuracy@1 0.000 (0.087)\tAccuracy@5 0.000 (0.503)\t\n","2022-05-17 09:45:26,760:[P:402]:Rank[0/1] =\u003e Epoch[0][1500/40038]: Time 0.273s (1.706s)\tSpeed 117.2 samples/s\tData 0.001s (1.409s)\tLoss 6.93703 (6.96178)\tAccuracy@1 3.125 (0.106)\tAccuracy@5 3.125 (0.558)\t\n","2022-05-17 09:59:35,818:[P:402]:Rank[0/1] =\u003e Epoch[0][2000/40038]: Time 0.283s (1.704s)\tSpeed 113.1 samples/s\tData 0.001s (1.409s)\tLoss 6.85747 (6.95901)\tAccuracy@1 0.000 (0.109)\tAccuracy@5 3.125 (0.590)\t\n","2022-05-17 10:13:29,077:[P:402]:Rank[0/1] =\u003e Epoch[0][2500/40038]: Time 0.304s (1.696s)\tSpeed 105.4 samples/s\tData 0.014s (1.402s)\tLoss 6.88297 (6.95565)\tAccuracy@1 0.000 (0.116)\tAccuracy@5 0.000 (0.610)\t\n","2022-05-17 10:27:32,995:[P:402]:Rank[0/1] =\u003e Epoch[0][3000/40038]: Time 5.127s (1.695s)\tSpeed 6.2 samples/s\tData 4.787s (1.400s)\tLoss 6.94662 (6.95227)\tAccuracy@1 0.000 (0.126)\tAccuracy@5 0.000 (0.631)\t\n","2022-05-17 10:41:15,581:[P:402]:Rank[0/1] =\u003e Epoch[0][3500/40038]: Time 0.277s (1.688s)\tSpeed 115.6 samples/s\tData 0.001s (1.391s)\tLoss 6.82960 (6.94941)\tAccuracy@1 3.125 (0.132)\tAccuracy@5 3.125 (0.658)\t\n","2022-05-17 10:55:09,964:[P:402]:Rank[0/1] =\u003e Epoch[0][4000/40038]: Time 4.539s (1.685s)\tSpeed 7.1 samples/s\tData 4.203s (1.388s)\tLoss 6.93496 (6.94697)\tAccuracy@1 0.000 (0.144)\tAccuracy@5 0.000 (0.677)\t\n","2022-05-17 11:09:14,056:[P:402]:Rank[0/1] =\u003e Epoch[0][4500/40038]: Time 0.281s (1.686s)\tSpeed 113.7 samples/s\tData 0.001s (1.389s)\tLoss 6.90473 (6.94501)\tAccuracy@1 0.000 (0.153)\tAccuracy@5 3.125 (0.707)\t\n","2022-05-17 11:23:14,242:[P:402]:Rank[0/1] =\u003e Epoch[0][5000/40038]: Time 2.820s (1.685s)\tSpeed 11.3 samples/s\tData 2.491s (1.388s)\tLoss 6.89126 (6.94252)\tAccuracy@1 3.125 (0.160)\tAccuracy@5 3.125 (0.725)\t\n","2022-05-17 11:37:16,027:[P:402]:Rank[0/1] =\u003e Epoch[0][5500/40038]: Time 0.271s (1.685s)\tSpeed 118.2 samples/s\tData 0.001s (1.388s)\tLoss 6.91232 (6.94062)\tAccuracy@1 0.000 (0.164)\tAccuracy@5 0.000 (0.740)\t\n","2022-05-17 11:51:12,709:[P:402]:Rank[0/1] =\u003e Epoch[0][6000/40038]: Time 2.149s (1.684s)\tSpeed 14.9 samples/s\tData 1.848s (1.386s)\tLoss 6.86691 (6.93872)\tAccuracy@1 0.000 (0.175)\tAccuracy@5 0.000 (0.756)\t\n","2022-05-17 12:05:33,135:[P:402]:Rank[0/1] =\u003e Epoch[0][6500/40038]: Time 0.266s (1.687s)\tSpeed 120.5 samples/s\tData 0.002s (1.389s)\tLoss 6.84469 (6.93688)\tAccuracy@1 0.000 (0.174)\tAccuracy@5 0.000 (0.765)\t\n","2022-05-17 12:19:47,931:[P:402]:Rank[0/1] =\u003e Epoch[0][7000/40038]: Time 3.761s (1.689s)\tSpeed 8.5 samples/s\tData 3.430s (1.391s)\tLoss 6.86710 (6.93523)\tAccuracy@1 0.000 (0.176)\tAccuracy@5 0.000 (0.778)\t\n","2022-05-17 12:34:16,104:[P:402]:Rank[0/1] =\u003e Epoch[0][7500/40038]: Time 3.675s (1.692s)\tSpeed 8.7 samples/s\tData 3.333s (1.395s)\tLoss 6.83389 (6.93343)\tAccuracy@1 0.000 (0.180)\tAccuracy@5 0.000 (0.798)\t\n","2022-05-17 12:49:15,123:[P:402]:Rank[0/1] =\u003e Epoch[0][8000/40038]: Time 0.260s (1.698s)\tSpeed 123.0 samples/s\tData 0.001s (1.402s)\tLoss 6.94423 (6.93189)\tAccuracy@1 0.000 (0.179)\tAccuracy@5 0.000 (0.809)\t\n","2022-05-17 13:04:41,144:[P:402]:Rank[0/1] =\u003e Epoch[0][8500/40038]: Time 9.905s (1.707s)\tSpeed 3.2 samples/s\tData 9.555s (1.411s)\tLoss 6.88299 (6.93053)\tAccuracy@1 0.000 (0.184)\tAccuracy@5 0.000 (0.829)\t\n","2022-05-17 13:20:06,130:[P:402]:Rank[0/1] =\u003e Epoch[0][9000/40038]: Time 0.265s (1.715s)\tSpeed 120.9 samples/s\tData 0.001s (1.419s)\tLoss 6.91655 (6.92922)\tAccuracy@1 0.000 (0.188)\tAccuracy@5 0.000 (0.844)\t\n","2022-05-17 13:35:40,125:[P:402]:Rank[0/1] =\u003e Epoch[0][9500/40038]: Time 0.272s (1.723s)\tSpeed 117.6 samples/s\tData 0.001s (1.428s)\tLoss 6.85740 (6.92807)\tAccuracy@1 0.000 (0.190)\tAccuracy@5 3.125 (0.854)\t\n","2022-05-17 13:51:25,816:[P:402]:Rank[0/1] =\u003e Epoch[0][10000/40038]: Time 0.265s (1.732s)\tSpeed 120.9 samples/s\tData 0.001s (1.437s)\tLoss 6.89732 (6.92664)\tAccuracy@1 0.000 (0.195)\tAccuracy@5 0.000 (0.870)\t\n","2022-05-17 14:07:31,529:[P:402]:Rank[0/1] =\u003e Epoch[0][10500/40038]: Time 0.261s (1.741s)\tSpeed 122.5 samples/s\tData 0.001s (1.447s)\tLoss 6.85802 (6.92560)\tAccuracy@1 0.000 (0.197)\tAccuracy@5 0.000 (0.881)\t\n","2022-05-17 14:23:10,688:[P:402]:Rank[0/1] =\u003e Epoch[0][11000/40038]: Time 0.280s (1.747s)\tSpeed 114.2 samples/s\tData 0.003s (1.453s)\tLoss 6.87825 (6.92428)\tAccuracy@1 0.000 (0.204)\tAccuracy@5 0.000 (0.902)\t\n","2022-05-17 14:39:10,794:[P:402]:Rank[0/1] =\u003e Epoch[0][11500/40038]: Time 0.266s (1.755s)\tSpeed 120.1 samples/s\tData 0.001s (1.461s)\tLoss 6.95697 (6.92324)\tAccuracy@1 0.000 (0.207)\tAccuracy@5 0.000 (0.908)\t\n","2022-05-17 14:55:02,783:[P:402]:Rank[0/1] =\u003e Epoch[0][12000/40038]: Time 0.275s (1.761s)\tSpeed 116.5 samples/s\tData 0.001s (1.467s)\tLoss 6.93251 (6.92203)\tAccuracy@1 0.000 (0.215)\tAccuracy@5 0.000 (0.924)\t\n","2022-05-17 15:10:59,539:[P:402]:Rank[0/1] =\u003e Epoch[0][12500/40038]: Time 0.262s (1.767s)\tSpeed 122.3 samples/s\tData 0.001s (1.473s)\tLoss 6.91506 (6.92108)\tAccuracy@1 0.000 (0.218)\tAccuracy@5 0.000 (0.938)\t\n","2022-05-17 15:27:00,013:[P:402]:Rank[0/1] =\u003e Epoch[0][13000/40038]: Time 3.999s (1.773s)\tSpeed 8.0 samples/s\tData 3.626s (1.479s)\tLoss 6.93740 (6.91997)\tAccuracy@1 0.000 (0.226)\tAccuracy@5 3.125 (0.953)\t\n","2022-05-17 15:43:12,146:[P:402]:Rank[0/1] =\u003e Epoch[0][13500/40038]: Time 0.274s (1.780s)\tSpeed 116.6 samples/s\tData 0.002s (1.486s)\tLoss 6.91363 (6.91906)\tAccuracy@1 0.000 (0.229)\tAccuracy@5 0.000 (0.963)\t\n","2022-05-17 15:59:27,251:[P:402]:Rank[0/1] =\u003e Epoch[0][14000/40038]: Time 0.273s (1.786s)\tSpeed 117.3 samples/s\tData 0.001s (1.492s)\tLoss 6.87633 (6.91808)\tAccuracy@1 0.000 (0.231)\tAccuracy@5 3.125 (0.972)\t\n","2022-05-17 16:16:00,954:[P:402]:Rank[0/1] =\u003e Epoch[0][14500/40038]: Time 10.743s (1.793s)\tSpeed 3.0 samples/s\tData 10.395s (1.499s)\tLoss 6.89088 (6.91711)\tAccuracy@1 3.125 (0.236)\tAccuracy@5 3.125 (0.983)\t\n","2022-05-17 16:32:24,005:[P:402]:Rank[0/1] =\u003e Epoch[0][15000/40038]: Time 0.268s (1.798s)\tSpeed 119.3 samples/s\tData 0.001s (1.505s)\tLoss 6.88855 (6.91621)\tAccuracy@1 0.000 (0.237)\tAccuracy@5 0.000 (0.997)\t\n","2022-05-17 16:48:36,612:[P:402]:Rank[0/1] =\u003e Epoch[0][15500/40038]: Time 0.268s (1.803s)\tSpeed 119.6 samples/s\tData 0.001s (1.510s)\tLoss 6.96101 (6.91532)\tAccuracy@1 0.000 (0.239)\tAccuracy@5 0.000 (1.010)\t\n","2022-05-17 17:04:59,155:[P:402]:Rank[0/1] =\u003e Epoch[0][16000/40038]: Time 4.872s (1.808s)\tSpeed 6.6 samples/s\tData 4.509s (1.515s)\tLoss 6.90021 (6.91438)\tAccuracy@1 0.000 (0.242)\tAccuracy@5 0.000 (1.017)\t\n","Traceback (most recent call last):\n","  File \"tools/train.py\", line 212, in \u003cmodule\u003e\n","    main()\n","  File \"tools/train.py\", line 139, in main\n","    scaler=scaler)\n","  File \"/content/drive/MyDrive/Colab_Notebooks/DSC3032_01/CvT/tools/../lib/core/function.py\", line 36, in train_one_epoch\n","    for i, (x, y) in enumerate(train_loader):\n","  File \"/root/.local/lib/python3.7/site-packages/timm/data/loader.py\", line 82, in __iter__\n","    for next_input, next_target in self.loader:\n","  File \"/root/.local/lib/python3.7/site-packages/timm/data/loader.py\", line 242, in __iter__\n","    yield next(self.iterator)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1065, in _next_data\n","    return self._process_data(data)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1111, in _process_data\n","    data.reraise()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 428, in reraise\n","    raise self.exc_type(msg)\n","PIL.UnidentifiedImageError: Caught UnidentifiedImageError in DataLoader worker process 0.\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n","    data = fetcher.fetch(index)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in \u003clistcomp\u003e\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\", line 151, in __getitem__\n","    sample = self.loader(path)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\", line 188, in default_loader\n","    return pil_loader(path)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\", line 169, in pil_loader\n","    img = Image.open(f)\n","  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2896, in open\n","    \"cannot identify image file %r\" % (filename if filename else fp)\n","PIL.UnidentifiedImageError: cannot identify image file \u003c_io.BufferedReader name='DATASET/imagenet/train/n01950731/n02093428/n02093428_10156.JPEG'\u003e\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 260, in \u003cmodule\u003e\n","    main()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 256, in main\n","    cmd=cmd)\n","subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'tools/train.py', '--local_rank=0', '--cfg', 'experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml']' returned non-zero exit status 1.\n"]}],"source":["!bash run.sh -g 1 -t train --cfg experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml"]},{"cell_type":"markdown","metadata":{"id":"lYzudMPcA3rP"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"idfULRW32z_c"},"outputs":[],"source":["# Saved model\n","test_model = ''\n","\n","# Test Saved model\n","!bash run.sh -g 1 -t test --cfg experiments/imagenet/cvt/cvt-13-224x224-b32-e3.yaml TEST.MODEL_FILE {test_model}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Om_yfXk9rcG"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHsingLSEi5Q"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtqYzg-qLaWs"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tL5wM8dziNoE"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVVK4BZeNmm5"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8e8a7f0lWLdD"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XtjOfJaXdibO"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_IKNv79kZ4L"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hp6Q1Vm1rRVL"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"itvrWnEFyIyZ"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0K27aPr5APP"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRM_eYWg_3sL"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rfPALi3TGvJH"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOK4W8BfLD/lGhU+UeLXVaQ","background_execution":"on","collapsed_sections":[],"mount_file_id":"1gZsh0Xu8Pr0AO_zTdgFknfOC7u5U0ZYQ","name":"FullTrain.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}